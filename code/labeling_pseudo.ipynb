{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3925,
     "status": "ok",
     "timestamp": 1569048264329,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "WS9tbtWWIbi-",
    "outputId": "762d227f-f783-444d-ebf7-1539d7714393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras import initializers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1520,
     "status": "ok",
     "timestamp": 1569048265993,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "TK-qUjJJIbjJ",
    "outputId": "ffe292a6-bf8a-41f8-cff6-bf0b7aba1486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data : 3000\n",
      "Bukan Dewasa : 1500\n",
      "Dewasa : 1500\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAHjCAYAAACabpOIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf7yUdGL8GZVXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_excel(\"data/clean/cleansampel.xlsx\")\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "dewasa = data.loc[data['label'] == 1, 'tweet'].copy().reset_index(drop=True)\n",
    "bukan = data.loc[data['label'] == 0, 'tweet'].copy().reset_index(drop=True)\n",
    "print(\"Total Data :\", len(data))\n",
    "print(\"Bukan Dewasa :\", len(bukan))\n",
    "print(\"Dewasa :\", len(dewasa))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(x='label', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8s0-cbOIbjP"
   },
   "outputs": [],
   "source": [
    "def get_model(X, Y):\n",
    "    model = Sequential() \n",
    "    model.add(Embedding(input_dim = vocab, output_dim = 128, input_length = maxlen, embeddings_initializer = initializer))\n",
    "    model.add(Dropout(0.9))\n",
    "    model.add(LSTM(128, recurrent_initializer = initializer, kernel_initializer = initializer))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2, activation='sigmoid', kernel_initializer = initializer)) \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluation(model, X, Y):\n",
    "    Y_pred = model.predict(X)\n",
    "    Y_pred_class = np.argmax(Y_pred, axis=1)\n",
    "    Y_act = Y\n",
    "    \n",
    "    acc = accuracy_score(Y_act, Y_pred_class)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7S0DuClIIbjd"
   },
   "outputs": [],
   "source": [
    "text = data['tweet'].values\n",
    "label = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpUSXTOSIbjg"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "vocab = max([len(tokenizer.word_index)]) + 1 # kamus kata \n",
    "maxlen = max([len(i.split()) for i in text]) # panjang kalimat\n",
    "batch_size = 32 # penentuan jumlah sampel yang ditraining pada tiap epoch\n",
    "num_epochs = 50 # banyak iterasi pada saat training model \n",
    "initializer = initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=2) # mengatur angka random weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Huk07ZmfIbjj"
   },
   "outputs": [],
   "source": [
    "#Data Train\n",
    "X = tokenizer.texts_to_sequences(text)\n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "Y = to_categorical(label, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1417,
     "status": "ok",
     "timestamp": 1568672202754,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "7Q0Nb6RmIbjp",
    "outputId": "cf349561-51aa-4e1e-9a25-71cded04ecb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 49, 128)           1018752   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,150,594\n",
      "Trainable params: 1,150,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 431489,
     "status": "ok",
     "timestamp": 1568672639508,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "Pgfk2MrYIbjv",
    "outputId": "877187cc-b24b-40be-8209-ed5ea7b47cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3000/3000 [==============================] - 10s 3ms/step - loss: 0.6149 - acc: 0.6838\n",
      "Epoch 2/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.2004 - acc: 0.9292\n",
      "Epoch 3/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0913 - acc: 0.9698\n",
      "Epoch 4/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0629 - acc: 0.9807\n",
      "Epoch 5/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0612 - acc: 0.9820\n",
      "Epoch 6/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0363 - acc: 0.9893\n",
      "Epoch 7/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0173 - acc: 0.9943\n",
      "Epoch 8/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0144 - acc: 0.9965\n",
      "Epoch 9/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0157 - acc: 0.9950\n",
      "Epoch 10/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0087 - acc: 0.9973\n",
      "Epoch 11/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0691 - acc: 0.9772\n",
      "Epoch 12/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0115 - acc: 0.9977\n",
      "Epoch 13/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0055 - acc: 0.9990\n",
      "Epoch 14/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0056 - acc: 0.9980\n",
      "Epoch 15/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 16/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 17/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 7.8502e-04 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 7.3991e-04 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0010 - acc: 0.9997\n",
      "Epoch 22/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 4.9021e-04 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.5196e-04 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 2.8478e-04 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0037 - acc: 0.9997\n",
      "Epoch 28/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 8.1100e-04 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.9867e-04 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 3.9608e-04 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.0606e-04 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 8.4741e-04 - acc: 0.9997\n",
      "Epoch 33/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 9.3060e-04 - acc: 0.9993\n",
      "Epoch 34/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.9630e-04 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.6705e-04 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 1.4705e-04 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.8491e-04 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 1.3282e-04 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 2.9381e-04 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 7.2433e-05 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 8.6944e-05 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 9.3620e-05 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 4.2896e-05 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 4.1093e-05 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 7.8456e-05 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 47/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 48/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 4.0368e-04 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "3000/3000 [==============================] - 9s 3ms/step - loss: 1.1258e-04 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "3000/3000 [==============================] - 8s 3ms/step - loss: 2.4141e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d24c3ea90>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training model\n",
    "model.fit(X, Y, batch_size=batch_size, epochs=num_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 263226,
     "status": "ok",
     "timestamp": 1568672641622,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "5DBUPTbMIbj4",
    "outputId": "22b20b0c-2044-4a49-e8de-ef47d796979f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "acc = evaluation(model, X, label)\n",
    "print(\"Accuracy: %.2f\" % (acc*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_Deb12uIbj-"
   },
   "outputs": [],
   "source": [
    "model.save('model/pseudo_labeling.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JGVpgWuIbkC"
   },
   "source": [
    "# Labeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfDbvZe1IbkD"
   },
   "outputs": [],
   "source": [
    "unlabeled = pd.read_excel(\"data/clean/cleandata.xlsx\")\n",
    "unlabeled.replace('', np.nan, inplace=True)\n",
    "unlabeled.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McD5tizCIbkJ"
   },
   "outputs": [],
   "source": [
    "un_text = unlabeled['tweet'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvnofKovIbkN"
   },
   "outputs": [],
   "source": [
    "text1 = tokenizer.texts_to_sequences(un_text)\n",
    "text1 = pad_sequences(text1, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7psjZki1IbkQ"
   },
   "outputs": [],
   "source": [
    "pred_label = model.predict(text1)\n",
    "label1 = np.argmax(pred_label, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-Bn3bwUIbkT"
   },
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('data/label/label_pseudo')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "rowHeaders = ['tweet', 'label']\n",
    "worksheet.write_row(row, col,  tuple(rowHeaders))\n",
    "\n",
    "\n",
    "for i in un_text:\n",
    "    tweet = i\n",
    "    rowValues = [tweet]\n",
    "    row += 1\n",
    "    worksheet.write_row(row, col, tuple(rowValues))\n",
    "\n",
    "row = 0\n",
    "for l in label1:\n",
    "    label = l\n",
    "    rowValues = [label]\n",
    "    row += 1 \n",
    "    worksheet.write_row(row, col + 1, tuple(rowValues))\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7JmHHjafIbkW"
   },
   "source": [
    "# Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RgE7_8EMIbka"
   },
   "outputs": [],
   "source": [
    "excel_names = [\"data/clean/cleansampel.xlsx\", \"data/label/label_pseudo.xlsx\"]\n",
    "excels = [pd.ExcelFile(name) for name in excel_names]\n",
    "\n",
    "# ubah ke data frame \n",
    "# hapus header pertama, yang merupakan judul kolom\n",
    "frames = [x.parse(x.sheet_names[0], header=None,index_col=None) for x in excels]\n",
    "frames[1:] = [df[1:] for df in frames[1:]]\n",
    "\n",
    "# menggabungkan dataframe\n",
    "combined = pd.concat(frames)\n",
    "\n",
    "# tulis/save ke file baru \n",
    "combined.to_excel(\"data/label/combineSSL1.xlsx\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C9vWtf2Ibke"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"data/label/combineSSL1.xlsx\")\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1132,
     "status": "ok",
     "timestamp": 1569048308373,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "awK0JXc2Ibkh",
    "outputId": "defb1203-d34e-4f45-ab34-5b58afea86ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data : 54338\n",
      "Bukan Dewasa : 27192\n",
      "Dewasa : 27146\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAHjCAYAAACq4oKpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDgBgOEEHADDc/wWEH33FvPXPrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dewasa = data.loc[data['label'] == 1, 'tweet'].copy().reset_index(drop=True)\n",
    "bukan = data.loc[data['label'] == 0, 'tweet'].copy().reset_index(drop=True)\n",
    "print(\"Total Data :\", len(data))\n",
    "print(\"Bukan Dewasa :\", len(bukan))\n",
    "print(\"Dewasa :\", len(dewasa))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(x='label', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGYHt9coIbkk"
   },
   "outputs": [],
   "source": [
    "text2 = data['tweet'].values\n",
    "label2 = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDichW8sIbkp"
   },
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(text2, label2, test_size = 0.33, random_state = 42)\n",
    "data_train, data_val, label_train, label_val = train_test_split(data_train, label_train, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlokvBOsIbky"
   },
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(data_train)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "Y_train = to_categorical(label_train, num_classes = 2)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(data_test)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "Y_test = to_categorical(label_test, num_classes = 2)\n",
    "\n",
    "X_val = tokenizer.texts_to_sequences(data_val)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "Y_val = to_categorical(label_val, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4684159,
     "status": "ok",
     "timestamp": 1569053002829,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "TpXMn2z7Ibk-",
    "outputId": "a98f64d0-5e7e-472d-9625-840dbe07af90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24392 samples, validate on 12014 samples\n",
      "Epoch 1/50\n",
      "24392/24392 [==============================] - 96s 4ms/step - loss: 0.2154 - acc: 0.9203 - val_loss: 0.1328 - val_acc: 0.9547\n",
      "Epoch 2/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.1385 - acc: 0.9509 - val_loss: 0.1222 - val_acc: 0.9569\n",
      "Epoch 3/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.1224 - acc: 0.9559 - val_loss: 0.1188 - val_acc: 0.9570\n",
      "Epoch 4/50\n",
      "24392/24392 [==============================] - 95s 4ms/step - loss: 0.1132 - acc: 0.9587 - val_loss: 0.1173 - val_acc: 0.9573\n",
      "Epoch 5/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.1067 - acc: 0.9610 - val_loss: 0.1133 - val_acc: 0.9567\n",
      "Epoch 6/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.1007 - acc: 0.9617 - val_loss: 0.1133 - val_acc: 0.9580\n",
      "Epoch 7/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0942 - acc: 0.9626 - val_loss: 0.1144 - val_acc: 0.9574\n",
      "Epoch 8/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0906 - acc: 0.9654 - val_loss: 0.1182 - val_acc: 0.9587\n",
      "Epoch 9/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0871 - acc: 0.9672 - val_loss: 0.1121 - val_acc: 0.9595\n",
      "Epoch 10/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0848 - acc: 0.9669 - val_loss: 0.1124 - val_acc: 0.9595\n",
      "Epoch 11/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0833 - acc: 0.9659 - val_loss: 0.1137 - val_acc: 0.9606\n",
      "Epoch 12/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0784 - acc: 0.9684 - val_loss: 0.1146 - val_acc: 0.9605\n",
      "Epoch 13/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0761 - acc: 0.9690 - val_loss: 0.1124 - val_acc: 0.9606\n",
      "Epoch 14/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0750 - acc: 0.9705 - val_loss: 0.1101 - val_acc: 0.9614\n",
      "Epoch 15/50\n",
      "24392/24392 [==============================] - 96s 4ms/step - loss: 0.0708 - acc: 0.9711 - val_loss: 0.1126 - val_acc: 0.9616\n",
      "Epoch 16/50\n",
      "24392/24392 [==============================] - 95s 4ms/step - loss: 0.0708 - acc: 0.9715 - val_loss: 0.1163 - val_acc: 0.9622\n",
      "Epoch 17/50\n",
      "24392/24392 [==============================] - 96s 4ms/step - loss: 0.0696 - acc: 0.9719 - val_loss: 0.1135 - val_acc: 0.9618\n",
      "Epoch 18/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0696 - acc: 0.9719 - val_loss: 0.1178 - val_acc: 0.9606\n",
      "Epoch 19/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0673 - acc: 0.9728 - val_loss: 0.1158 - val_acc: 0.9615\n",
      "Epoch 20/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0653 - acc: 0.9728 - val_loss: 0.1184 - val_acc: 0.9611\n",
      "Epoch 21/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0643 - acc: 0.9727 - val_loss: 0.1211 - val_acc: 0.9605\n",
      "Epoch 22/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0622 - acc: 0.9739 - val_loss: 0.1217 - val_acc: 0.9609\n",
      "Epoch 23/50\n",
      "24392/24392 [==============================] - 95s 4ms/step - loss: 0.0621 - acc: 0.9740 - val_loss: 0.1217 - val_acc: 0.9606\n",
      "Epoch 24/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0595 - acc: 0.9752 - val_loss: 0.1303 - val_acc: 0.9600\n",
      "Epoch 25/50\n",
      "24392/24392 [==============================] - 92s 4ms/step - loss: 0.0579 - acc: 0.9757 - val_loss: 0.1245 - val_acc: 0.9602\n",
      "Epoch 26/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0594 - acc: 0.9754 - val_loss: 0.1216 - val_acc: 0.9612\n",
      "Epoch 27/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0586 - acc: 0.9751 - val_loss: 0.1301 - val_acc: 0.9602\n",
      "Epoch 28/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0571 - acc: 0.9755 - val_loss: 0.1269 - val_acc: 0.9615\n",
      "Epoch 29/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0569 - acc: 0.9756 - val_loss: 0.1350 - val_acc: 0.9580\n",
      "Epoch 30/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0563 - acc: 0.9766 - val_loss: 0.1254 - val_acc: 0.9615\n",
      "Epoch 31/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0537 - acc: 0.9763 - val_loss: 0.1362 - val_acc: 0.9602\n",
      "Epoch 32/50\n",
      "24392/24392 [==============================] - 95s 4ms/step - loss: 0.0550 - acc: 0.9767 - val_loss: 0.1271 - val_acc: 0.9616\n",
      "Epoch 33/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0519 - acc: 0.9769 - val_loss: 0.1401 - val_acc: 0.9618\n",
      "Epoch 34/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0538 - acc: 0.9767 - val_loss: 0.1315 - val_acc: 0.9601\n",
      "Epoch 35/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0527 - acc: 0.9774 - val_loss: 0.1333 - val_acc: 0.9595\n",
      "Epoch 36/50\n",
      "24392/24392 [==============================] - 92s 4ms/step - loss: 0.0520 - acc: 0.9781 - val_loss: 0.1437 - val_acc: 0.9608\n",
      "Epoch 37/50\n",
      "24392/24392 [==============================] - 92s 4ms/step - loss: 0.0516 - acc: 0.9781 - val_loss: 0.1369 - val_acc: 0.9595\n",
      "Epoch 38/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0512 - acc: 0.9779 - val_loss: 0.1370 - val_acc: 0.9593\n",
      "Epoch 39/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0502 - acc: 0.9775 - val_loss: 0.1435 - val_acc: 0.9600\n",
      "Epoch 40/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0485 - acc: 0.9796 - val_loss: 0.1489 - val_acc: 0.9605\n",
      "Epoch 41/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0515 - acc: 0.9780 - val_loss: 0.1377 - val_acc: 0.9600\n",
      "Epoch 42/50\n",
      "24392/24392 [==============================] - 92s 4ms/step - loss: 0.0518 - acc: 0.9788 - val_loss: 0.1373 - val_acc: 0.9602\n",
      "Epoch 43/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0468 - acc: 0.9789 - val_loss: 0.1671 - val_acc: 0.9580\n",
      "Epoch 44/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0487 - acc: 0.9786 - val_loss: 0.1588 - val_acc: 0.9584\n",
      "Epoch 45/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0462 - acc: 0.9793 - val_loss: 0.1512 - val_acc: 0.9605\n",
      "Epoch 46/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0461 - acc: 0.9810 - val_loss: 0.1481 - val_acc: 0.9599\n",
      "Epoch 47/50\n",
      "24392/24392 [==============================] - 94s 4ms/step - loss: 0.0487 - acc: 0.9797 - val_loss: 0.1358 - val_acc: 0.9612\n",
      "Epoch 48/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0476 - acc: 0.9796 - val_loss: 0.1480 - val_acc: 0.9606\n",
      "Epoch 49/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0460 - acc: 0.9809 - val_loss: 0.1542 - val_acc: 0.9598\n",
      "Epoch 50/50\n",
      "24392/24392 [==============================] - 93s 4ms/step - loss: 0.0442 - acc: 0.9813 - val_loss: 0.1461 - val_acc: 0.9606\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4711119,
     "status": "ok",
     "timestamp": 1569053038754,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "kZHN_CmwIblB",
    "outputId": "63afab87-0bbf-44e6-acf8-4b526494b62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98.75 %\n"
     ]
    }
   ],
   "source": [
    "acc_train = evaluation(model, X_train, label_train)\n",
    "print(\"Train Accuracy: %.2f\" % (acc_train*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4721728,
     "status": "ok",
     "timestamp": 1569053049875,
     "user": {
      "displayName": "ANISA MILADYA HAKIM -",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAxiDFPChsKSUff6d_ZwtaHRXcazNCoPnwSRHwN=s64",
      "userId": "03112180736924655103"
     },
     "user_tz": -420
    },
    "id": "U_JNKK2WIblG",
    "outputId": "cdaf0a0a-e4da-41bc-f9f4-c453bde92146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.28 %\n"
     ]
    }
   ],
   "source": [
    "acc_test = evaluation(model, X_test, label_test)\n",
    "print(\"Test Accuracy: %.2f\" % (acc_test*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvVqoV5tIblL"
   },
   "outputs": [],
   "source": [
    "model.save('model/pseudo_validation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6glsHVJmIblP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "labeling_pseudo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
